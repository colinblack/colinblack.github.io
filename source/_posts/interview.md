---
title: interview
date: 2020-08-03 20:16:31
tags: 面试
---

## 消息队列　
### 为什么使用消息队列　
1. 解耦
解耦前:  
![interview_2020080401](https://i.loli.net/2020/11/15/L2mjEoezUJ87sGy.png)  
解耦后:  
![interview_2020080402](https://i.loli.net/2020/11/15/S1gNdUCF8ZEbM5X.png)  

2. 异步  
同步:  
![interview_2020080403](https://i.loli.net/2020/11/15/9Z3ipqUPI1R4AaQ.png)  

异步:  
![interview_2020080404](https://i.loli.net/2020/11/15/toDG9L1z3yEOu5B.png)  


3. 削峰    
削峰前:   
![interview_2020080405](https://i.loli.net/2020/11/15/Fc8ISDesT2o3dGV.png)  

削峰后:  
![interview_2020080406](https://i.loli.net/2020/11/15/ENX4bsKlcG7DhwC.png)  

### 消息队列优缺点　　
![interview_2020080407](https://i.loli.net/2020/11/15/BbnIu4KMaYrSeZv.png)  



### kafka, activemq, rabbitmq, rocketmq都有哪些优缺点　　
| 特性                    | ActiveMQ                                                     | RabbitMQ                                                     | RocketMQ                                                     | Kafka                                                        |
| :---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量              | 万级，吞吐量比RocketMQ和Kafka要低了一个数量级                | 万级，吞吐量比RocketMQ和Kafka要低了一个数量级                | 10万级，RocketMQ也是可以支撑高吞吐的一种MQ                   | 10万级别，这是kafka最大的优点，就是吞吐量高。 一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic数量对吞吐量的影响 |                                                              |                                                              | topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降 这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic | topic从几十个到几百个的时候，吞吐量会大幅度下降 所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源 |
| 时效性                  | ms级                                                         | 微秒级，这是rabbitmq的一大特点，延迟是最低的                 | ms级                                                         | 延迟在ms级以内                                               |
| 可用性                  | 高，基于主从架构实现高可用性                                 | 高，基于主从架构实现高可用性                                 | 非常高，分布式架构                                           | 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性              | 有较低的概率丢失数据                                         |                                                              | 经过参数优化配置，可以做到0丢失                              | 经过参数优化配置，消息可以做到0丢失                          |
| 功能支持                | MQ领域的功能极其完备                                         | 基于erlang开发，所以并发能力很强，性能极其好，延时很低       | MQ功能较为完善，还是分布式的，扩展性好                       | 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 |
| 优劣势总结              | 非常成熟，功能强大，在业内大量的公司以及项目中都有应用 偶尔会有较低概率丢失消息 而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本 而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用 | erlang语言开发，性能极其好，延时很低； 吞吐量到万级，MQ功能比较完备 而且开源提供的管理界面非常棒，用起来很好用 社区相对比较活跃，几乎每个月都发布几个版本分 在国内一些互联网公司近几年用rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。 而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。 | 接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的 | kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集 |

消息队列技术选型　  
中小型公司　RabbitMQ  
大型公司，基础架构研发实力较强　RocketMQ  
大数据领域的实时计算、日志采集等场景　Kafka  


### 消息队列如何保证高可用　
* RabbitMQ的高可用性　　
　rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式　
1. 单机模式　
生产没人用单机模式　


2. 普通集群模式　
![interview_2020080501](https://i.loli.net/2020/11/15/cSLZMTBUCwDOa5h.png)  

3. 镜像集群模式
![interview_2020080502](https://i.loli.net/2020/11/15/EemrsOtKDALGnBa.png)  
如何开启:在管理控制界面新增策略，要求数据同步到所有节点的，也可以要求就同步到指定数量的节点　　

* Kafka的高可用　
![interview_2020080503](https://i.loli.net/2020/11/15/SNdLHPMDcuKUnsb.png)  

### 从消息队列消费到重复数据怎么办　
消息队列都可能提供重复数据，这个要自己保证　
![interview_2020080504](https://i.loli.net/2020/11/15/xcyIa1hnmzsDbSP.png)  

如何保证数据幂等性　  
![interview_2020080505](https://i.loli.net/2020/11/15/4179saGnEh8qHXZ.png)     
幂等性: 重复多次请求保证数据状态不出错(例如数据重复,数据改变) 
方案

1. 根据主键查，如果数存在则不插入 
2. 写redis,　天然幂等　
3. 生产者发送每条数据时，加一个全局唯一的id，类似订单id，消费者拿到id后先根据id查询(比如查redis)
   ,如果没有数据，则将id写入redis,　否则不处理　


### 发送消息队列的数据丢了怎么办　
#### rabbitmq 
* 生产者弄丢数据　
生产者发送数据时可能由于网络问题,　在消息队列收到之前弄丢了，有两种方法解决
1. rabbitmq事务功能　
开启事务(channel.txSelect), 发送消息如果没有被rabbitmq收到，生产者会收到异常,　此时回滚事务(channel.txRollback), 重发, 如果接收到提交事务(channel.txCommit)
缺点: 降低吞吐量, 耗性能　

2. confirm 模式　
生产者设置confirm后, 每次发消息会分配一个唯一id, 如果写入rabbitmq会传回一个ack消息，如果rabbitmq没有处理，会回调生产者注册的nack接口，然后重试.　生产者可以在内存里维护每个消息id状态, 超过时间没收到消息回调，可以重发 

事务同步，阻塞
confirm 异步，非阻塞　

* rabbitmq弄丢数据　
开启持久化, 极小概率下rabbitmq没持久化完自己挂了导致少量数据丢失　

设置持久化方法
1. 创建queue时持久化，这样能保证持久化元数据，但是不能持久化数据本身
2. 发送消息时设置deliveryMode=2,此时会将消息持久化到磁盘.
必须同时设置这两个持久化,　rabbitmq挂了重启后会从磁盘上恢复queue里面的数据　

持久化配合confirm
只有消息被持久化到磁盘后才ack

缺点:
开启持久化也可能有数据丢失现象, 当消息写到rabbitmq后没来得及持久化, 此时rabbitmq挂了导致数据丢失　

* 消费者丢失数据　　
  收到数据还没消费进程挂了, 数据丢失, 此时使用rabbitmq的ack机制
  首先关闭rabbitmq自动ack, 自己处理完消息再主动ack
  
  

rabbitmq 丢数据情况　
    <img src="https://i.loli.net/2020/08/11/3kZ2WGNTSzxuy7v.png"/>


#### kafka 

kafka 某个broker宕机, 然后重新选举partiton的leader时, 刚好数据没有同步，此时leader挂了,然后选举某了follorer成leader, 造成一部分数据丢失　
为保证数据不丢要设置４个参数:
1. 给topic设置replication.factor>1, 每个partition至少２个副本
2. min.insync.replicas>1, 一个leader至少感知一个follower还和自己保持联系
3. producer端acks=all, 每条数据必须写入所有replica后才能认为写成功　
4. producer端设置retries=Max, 一旦写入失败，无限重试　　

生产者不会丢数据
如果按照上述的思路设置了ack=all，一定不会丢，要求是，leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果条件不满足，生产者会不断的重试无限次

kfka 丢数据情况
<img src="https://i.loli.net/2020/08/11/BnyzJCSPtmVbTFM.png"/>

### 如何保证消息的顺序　
#### 顺序错乱的场景　
1. rabbitmq
多个消费者从一个queue里面读数据
<img src="https://i.loli.net/2020/08/11/nUSD8KyliE7IZMN.png"/>

2. kafka
－个topic,　一个partition, －个consumer,内存多线程数据乱掉
<img src="https://i.loli.net/2020/08/11/lU9fbJqWs2YcCLo.png"/>


#### 解决　
1. rabbitmq
拆分多个queue，每个queue一个consumer，或者一个队列对应一个consumer, 内部用内存队列做排队, 分发给底层不同的worker来处理
<img src="https://i.loli.net/2020/08/11/ZvkeipAzFfbnj8R.png"/>

2. kafka
一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，N个线程分别消费一个内存queue即可
<img src="https://i.loli.net/2020/08/11/rRAukDibUgj5tqc.png"/>

### 消息积压怎么办
* 问题的实质是消费端出了问题，解决思路如下:
1. 先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉
2. 新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量
3. 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue
4. 临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据
5. 这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据
6. 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息

* 如果使用的是rabbitmq,而且设置了过期时间(TTL)，消息在queue中积压超过一定时间被清理掉了
批量重导, 将积压的数据丢掉, 等高峰期过后, 将丢掉的数据找回重新导入mq里

* 如果使用方法１后积压消息很长时间还是没处理, 导致mq快写满　
　只能接消费一个丢弃一个, 快速消费数据, 再执行方案2  
　<img src="https://i.loli.net/2020/08/12/ubWdyjXxhLA4i2P.png"/>

### 如何设计消息队列　
　1. mq支持伸缩性, 能快速扩容, 就可以增加吞吐量和容量, 可以参考kafka设计理念做成分布式系统, broker->topic->partition, 每个partition放一个机器, 存一部分数据, 如果现在资源不够, 给topic增加partition, 然后后做数据迁移, 增加机器　
　2. 要考虑持久化, 顺序写磁盘,　这样没有磁盘随机读写的寻址开销, 性能就提高了(kafka思路)
　3. 可用性, 要保证高可用, 参考kafka怎样保证高可用
　4. 数据0丢失


## 分布式缓存　
### 项目中如何使用缓存　






